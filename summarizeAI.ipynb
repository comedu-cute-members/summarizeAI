{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:24:49.200227Z",
     "start_time": "2022-11-17T05:24:37.082035Z"
    },
    "id": "DCoRPSSDMOSN"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "임포트\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T10:03:33.824750Z",
     "start_time": "2022-11-16T10:03:31.166837Z"
    },
    "id": "gov2I1jKMOSO"
   },
   "source": [
    "\"\"\"\n",
    "데이터 파싱\n",
    "\"\"\"\n",
    "values = []\n",
    "def parse_file_content(root_path, is_summary, section, file_count):\n",
    "    folder_sort = [\"News Articles\", \"Summaries\"]\n",
    "\n",
    "    if is_summary:\n",
    "        index = 1\n",
    "    else:\n",
    "        index = 0\n",
    "   \n",
    "    # 파일 열기\n",
    "    file_name = ('%d' % file_count).zfill(3) + '.txt'\n",
    "    path = \"%s/%s/%s/%s\" % (root_path, folder_sort[index], section, file_name)\n",
    "    file = open(path, 'r')\n",
    "\n",
    "    # 파일 읽어서 content에 넣기\n",
    "    lines = file.readlines()\n",
    "    content = ''\n",
    "    for line in lines:\n",
    "        content = content + ' ' + line.strip()\n",
    "        content = re.sub(r\"([?.!,])\", r\" \\1 \", content)\n",
    "        content = re.sub(\"[^ A-Za-z0-9?.!,$%]+\", '', content)\n",
    "        content = content.strip()\n",
    "\n",
    "    # 파일 닫기\n",
    "    file.close()\n",
    "\n",
    "    # 파일 내용 반환\n",
    "    return content\n",
    "  \n",
    "def parse_folder(root_path, section):\n",
    "    folder_path = \"%s/Summaries/%s/\" % (root_path, section)\n",
    "    file_list = os.listdir(folder_path)\n",
    "    max_file_count = len(file_list)\n",
    "  \n",
    "    for i in range(1, max_file_count + 1):\n",
    "        # Text 데이터 가져오기\n",
    "        text = parse_file_content(root_path=root_path, is_summary=False, section=section, file_count=i)\n",
    "    \n",
    "        # Summary 데이터 가져오기\n",
    "        summary = parse_file_content(root_path=root_path, is_summary=True, section=section, file_count=i)\n",
    "\n",
    "        # values에 데이터 넣기\n",
    "        values.append([text, summary])\n",
    "\n",
    "# 모든 섹션들 데이터에 넣기\n",
    "root_path = \"./BBC News Summary\"\n",
    "parse_folder(root_path, \"business\")\n",
    "parse_folder(root_path, \"entertainment\")\n",
    "parse_folder(root_path, \"politics\")\n",
    "parse_folder(root_path, \"sport\")\n",
    "parse_folder(root_path, \"tech\")\n",
    "\n",
    "# 데이터프레임 만들어 csv 파일로 저장\n",
    "df = pd.DataFrame(values)\n",
    "df.columns = [\"Text\", \"Summary\"]\n",
    "df.to_csv(\"News.csv\", index=False)\n",
    "df.to_csv(\"News_text.txt\", sep=\" \", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:24:56.221467Z",
     "start_time": "2022-11-17T05:24:56.075606Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DomdcrVhMOSP",
    "outputId": "e99191ce-04a1-4739-da31-b88d24a54dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 갯수 : 2225\n",
      "We need at least $20bn 10 . 6bn in investment and part of this has to come as foreign direct investment ,  said Mr Maran . Potential foreign investors will however need government approval before they increase their stake beyond 49% ,  Mr Maran said . Communications Minister Dayanidhi Maran said that there is a need to fund the fastgrowing mobile market . India has raised the limit for foreign direct investment in telecoms companies from 49% to 74% . Investment bank Morgan Stanley has forecast that Indias mobile market is likely to grow by about 40% a year until 2007 .\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "전처리\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"News.csv\")\n",
    "\n",
    "# print(df)\n",
    "print(\"전체 데이터 갯수 :\", len(df))\n",
    "# print(df.isnull().sum())\n",
    "print(df[\"Summary\"][18]) # UTF-8 인코딩이 유로 표시를 '짙'으로 바꿈, 영어 빼고 제외시킬 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:25:01.167809Z",
     "start_time": "2022-11-17T05:24:59.156153Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjVw7TNeMOSQ",
    "outputId": "2499f0e3-7478-4d65-bd37-83f5fa5f685e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeWarner said fourth quarter sales rose 2% to $11 . 1bn from $10 . 9bn . For the fullyear ,  TimeWarner posted a profit of $3 . 36bn ,  up 27% from its 2003 performance ,  while revenues grew 6 . 4% to $42 . 09bn . Quarterly profits at US media giant TimeWarner jumped 76% to $1 . 13bn 600m for the three months to December ,  from $639m yearearlier . However ,  the company said AOLs underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues . Its profits were buoyed by oneoff gains which offset a profit dip at Warner Bros ,  and less users for AOL . For 2005 ,  TimeWarner is projecting operating earnings growth of around 5% ,  and also expects higher revenue and wider profit margins . It lost 464 , 000 subscribers in the fourth quarter profits were lower than in the preceding three quarters . Time Warners fourth quarter profits were slightly better than analysts expectations .\n",
      "[0, 26, 55, 658, 2005, 133, 1]\n",
      "hi my name is\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for content in df['Text']:\n",
    "    texts.append(content)\n",
    "\n",
    "summaries = []\n",
    "for content in df['Summary']:\n",
    "    summaries.append(content)\n",
    "\n",
    "print(summaries[0])\n",
    "# 단어 모음 생성\n",
    "tokenizer = BertWordPieceTokenizer(clean_text=True, lowercase=True)\n",
    "tokenizer.train(files=\"News_text.txt\", vocab_size = 8000, special_tokens = [\n",
    "    \"[SOS]\", \"[EOS]\",\n",
    "])\n",
    "\n",
    "print(tokenizer.encode(\"[SOS] hi my name is [EOS]\").ids)\n",
    "print(tokenizer.decode(tokenizer.encode(\"[SOS] hi my name is [EOS]\").ids))\n",
    "\n",
    "START_TOKEN, END_TOKEN = [0], [1]  # <sos> 와 <eos>\n",
    "VOCAB_SIZE = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:25:14.570247Z",
     "start_time": "2022-11-17T05:25:08.174615Z"
    },
    "id": "t1HBzUgiMOSR"
   },
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 1000\n",
    "MAX_OUTPUT_LENGTH = 600\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    # 시작 토큰(sos)과 종료 토큰(eos) 포함\n",
    "    for (content1, content2) in zip(inputs, outputs):\n",
    "        content1 = START_TOKEN + tokenizer.encode(content1).ids + END_TOKEN\n",
    "        content2 = START_TOKEN + tokenizer.encode(content2).ids + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(content1)\n",
    "        tokenized_outputs.append(content2)\n",
    "    \n",
    "    # 길이를 1000, 600으로 맞춘다. 더 짧은 배열은 뒤에 0을 추가한다.\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=MAX_INPUT_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=MAX_OUTPUT_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "tok_texts, tok_summaries = tokenize_and_filter(texts, summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:25:17.198110Z",
     "start_time": "2022-11-17T05:25:17.181130Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlGEoN1cMOSR",
    "outputId": "aec62ad9-41fa-4e6d-9ee3-5cd18da70315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 데이터의 크기(shape) : (2225, 1000)\n",
      "요약 데이터의 크기(shape) : (2225, 600)\n"
     ]
    }
   ],
   "source": [
    "print(\"기사 데이터의 크기(shape) :\", tok_texts.shape)\n",
    "print(\"요약 데이터의 크기(shape) :\", tok_summaries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T05:25:23.802689Z",
     "start_time": "2022-11-17T05:25:23.753445Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTxfXCesMOSR",
    "outputId": "e8ea550f-08bf-46b3-9ff6-d23c2a38f59c"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'enc_inputs': tok_texts,\n",
    "        'dec_inputs': tok_summaries[:, :-1] # 마지막 패딩 0 제거\n",
    "    },\n",
    "    {\n",
    "        'outputs': tok_summaries[:, 1:] # 시작 토큰 제거\n",
    "    }\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "test_dataset = dataset.take(49)   # 앞에서 49개를 테스트 데이터로 뺌\n",
    "dataset = dataset.skip(49)   # 나머지 2176개가 학습 데이터가 됨\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # 메모리 사용을 위한 prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3K1gJeoMOSS"
   },
   "source": [
    "## transformer 아키텍처 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:17:22.192542Z",
     "start_time": "2022-11-17T08:17:22.169395Z"
    },
    "id": "YgbOK1gCMOSS"
   },
   "outputs": [],
   "source": [
    "# 인코더&디코더(포지셔널 인코딩)\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model, name=\"Positional_Encoding\"):\n",
    "        super(PositionalEncoding, self).__init__(name=name)\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        return position * (1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)))\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position = tf.range(position, dtype = tf.float32)[:, tf.newaxis],\n",
    "            i = tf.range(d_model, dtype = tf.float32)[tf.newaxis, :],\n",
    "            d_model = d_model\n",
    "        )\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines # even index -> sin\n",
    "        angle_rads[:, 1::2] = cosines # odd index  -> cos\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:17:22.395767Z",
     "start_time": "2022-11-17T08:17:22.376512Z"
    },
    "id": "naDI940YMOST"
   },
   "outputs": [],
   "source": [
    "# 패딩 마스크 생성\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x,0), tf.float32) # [[1,2,0,2,1]] => [[0.,0.,1.,0.,0.]]\n",
    "    return mask[:,tf.newaxis, tf.newaxis, :] # 차원 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:17:22.582049Z",
     "start_time": "2022-11-17T08:17:22.573548Z"
    },
    "id": "lduANA-XMOSU"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1] # [[1,2,0]] => 3\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) # 모든 원소가 1인 하삼각행렬\n",
    "    padding_mask = create_padding_mask(x) # x에서 0이었던 부분만 1로 바꿔진 행렬\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:17:22.801745Z",
     "start_time": "2022-11-17T08:17:22.775408Z"
    },
    "id": "0J4ViLosMOSU"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, d_model, num_heads, name=\"Multi_Head_Attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0 # d_model 사이즈의 행렬을 num_heads로 나눠야하기 때문\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # WQ, WK, WV 정의 : d_model 길이의 밀집층(가중치 행렬)\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model) # WQ (size: d_model * d_k)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model) # WK (size: d_model * d_k)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model) # WV (size: d_model * d_v)\n",
    "        \n",
    "        # WO\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model) # size: transpose hd_v * d_model\n",
    "    \n",
    "    def call(self, query, key, value, mask):\n",
    "\n",
    "        # 신경망 지나기\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 헤드 나누기\n",
    "        query = tf.reshape(query, shape=(self.batch_size, -1, self.num_heads, self.depth))\n",
    "        key = tf.reshape(key, shape=(self.batch_size, -1, self.num_heads, self.depth))\n",
    "        value = tf.reshape(value, shape=(self.batch_size, -1, self.num_heads, self.depth))\n",
    "        \n",
    "        query = tf.transpose(query, perm=[0,2,1,3])\n",
    "        key = tf.transpose(key, perm=[0,2,1,3])\n",
    "        value = tf.transpose(value, perm=[0,2,1,3])\n",
    "\n",
    "        #스케일 닷 프로덕트 어텐션\n",
    "        multiple_QandK = tf.matmul(query, key, transpose_b=True) # 행렬 곱셈\n",
    "        d_k = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    \n",
    "        # 어텐션 에너지\n",
    "        energy = multiple_QandK / (d_k ** 0.5)\n",
    "        \n",
    "        # mask multihead attention 일 때\n",
    "        if mask is not None :\n",
    "            energy += (mask * -1e10)\n",
    "\n",
    "        # 어텐션 스코어\n",
    "        attention_weights = tf.nn.softmax(energy, axis = -1)\n",
    "\n",
    "        # scaled dot product attention\n",
    "        scaled_dot_attention = tf.transpose(tf.matmul(attention_weights, value), perm=[0,2,1,3]) # 행렬 곱셈\n",
    "\n",
    "        # concat \n",
    "        concat_attention = tf.reshape(scaled_dot_attention, (self.batch_size, -1, self.d_model))\n",
    "\n",
    "        # WO 밀집층 레이어 지나기\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:17:55.749468Z",
     "start_time": "2022-11-17T08:17:55.721907Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, dff, d_model, num_heads, dropout, name, epsilon=1e-6):\n",
    "        super(EncoderLayer, self).__init__(name=name)\n",
    "        self.batch_size = batch_size\n",
    "        self.dff = dff\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # layers\n",
    "        self.multi_head_attention = MultiHeadAttention(self.batch_size, self.d_model, self.num_heads)\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
    "        self.FFN1 = tf.keras.layers.Dense(units=self.dff, activation='relu')\n",
    "        self.FFN2 = tf.keras.layers.Dense(units=self.d_model)\n",
    "        \n",
    "    def call(self, inputs, padding_mask):\n",
    "        \n",
    "        # input size == output size\n",
    "        # dropout after each sublayer\n",
    "        \n",
    "        # first sub layer - Multi-head Attention\n",
    "        attention = self.multi_head_attention(query=inputs, key=inputs, value=inputs, mask=padding_mask)\n",
    "        attention = tf.keras.layers.Dropout(rate=self.dropout)(attention)\n",
    "        \n",
    "        # add, normalization\n",
    "        attention_norm = self.norm(inputs + attention)\n",
    "\n",
    "        # second sub layer - Feed Forward layer\n",
    "        outputs = self.FFN1(attention_norm)\n",
    "        outputs = self.FFN2(outputs)\n",
    "        outputs = tf.keras.layers.Dropout(rate=self.dropout)(outputs)\n",
    "\n",
    "        # add, normalization\n",
    "        outputs = self.norm(attention_norm + outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:47.300560Z",
     "start_time": "2022-11-17T08:18:47.292478Z"
    },
    "id": "xLctdIq6MOSU"
   },
   "outputs": [],
   "source": [
    "# real 인코더\n",
    "def encoder(batch_size, vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # input embedding, positional encoding\n",
    "    input_embedded = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
    "    input_embedded *= tf.cast(d_model, tf.float32) ** 0.5\n",
    "    input_positional_encoded = PositionalEncoding(position=vocab_size, d_model=d_model)(input_embedded)\n",
    "    enc_outputs = tf.keras.layers.Dropout(rate=dropout)(input_positional_encoded)\n",
    "    \n",
    "    # encoder layer * N\n",
    "    for i in range(num_layers):\n",
    "        enc_outputs = EncoderLayer(batch_size, dff, d_model, num_heads, dropout, \"encoder_layer_\"+str(i))(enc_outputs, padding_mask)\n",
    "            \n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=enc_outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaP9rLUKMOSV"
   },
   "source": [
    "## 디코더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:47.814613Z",
     "start_time": "2022-11-17T08:18:47.800064Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, dff, d_model, num_heads, dropout,  name, epsilon=1e-6):\n",
    "        super(DecoderLayer, self).__init__(name=name)\n",
    "        self.batch_size = batch_size\n",
    "        self.dff = dff\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # layers\n",
    "        self.masked_attention = MultiHeadAttention(self.batch_size, self.d_model, self.num_heads, name=\"Multi_Head_Attention_1\")\n",
    "        self.encoder_decoder_attention = MultiHeadAttention(self.batch_size, self.d_model, self.num_heads, name=\"Multi_Head_Attention_2\")\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
    "        self.FFN1 = tf.keras.layers.Dense(units=self.dff, activation=\"relu\")\n",
    "        self.FFN2 = tf.keras.layers.Dense(units=self.d_model)\n",
    "    \n",
    "    def call(self, inputs, enc_outputs, look_ahead_mask, padding_mask):\n",
    "        \n",
    "        # input size == output size\n",
    "        # dropout after each sublayer\n",
    "        \n",
    "        # first sub layer - masked multi-head attention\n",
    "        attention1 = self.masked_attention(query=inputs, key=inputs, value=inputs, mask=look_ahead_mask)\n",
    "\n",
    "        # add, normorlization\n",
    "        attention1 = self.norm(attention1 + inputs)\n",
    "\n",
    "        # second sub layer - encoder-decoder attention\n",
    "        attention2 = self.encoder_decoder_attention(query=attention1, key=enc_outputs, value=enc_outputs, mask=padding_mask)\n",
    "        attention2 = tf.keras.layers.Dropout(rate=self.dropout)(attention2)\n",
    "\n",
    "        # add, normorlization\n",
    "        attention2 = self.norm(attention2 + attention1)\n",
    "\n",
    "        # third sub layer - Feed Forward layer (dense layer)\n",
    "        feed_forward_output = self.FFN1(attention2)\n",
    "        feed_forward_output = self.FFN2(feed_forward_output)\n",
    "        feed_forward_output = tf.keras.layers.Dropout(rate=self.dropout)(feed_forward_output)\n",
    "\n",
    "        # add, normorlization\n",
    "        outputs = self.norm(attention2 + feed_forward_output)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:48.109357Z",
     "start_time": "2022-11-17T08:18:48.087235Z"
    },
    "id": "jgqFA45fMOSV"
   },
   "outputs": [],
   "source": [
    "def decoder(batch_size, vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    # output embedding\n",
    "    output_embedded = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
    "    output_embedded *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    output_embedded = PositionalEncoding(position=vocab_size, d_model=d_model)(output_embedded)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(output_embedded)\n",
    "    \n",
    "    # decoder layer * N\n",
    "    for i in range(num_layers):\n",
    "        dec_outputs = DecoderLayer(batch_size, dff, d_model, num_heads, dropout, \"decoder_layer_\"+str(i))(dec_outputs, enc_outputs, look_ahead_mask, padding_mask)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask], outputs=dec_outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sTDhtTNMOSV"
   },
   "source": [
    "## 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:48.920140Z",
     "start_time": "2022-11-17T08:18:48.897956Z"
    },
    "id": "OCUDKICKMOSV"
   },
   "outputs": [],
   "source": [
    "def transformer(encoder, decoder, vocab_size, name=\"transformer\"):\n",
    "    \n",
    "    # encoder input (type: keras tensor)\n",
    "    enc_inputs = tf.keras.Input(shape=(None,), name=\"enc_inputs\")\n",
    "\n",
    "    # decoder input (type: keras tensor)\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(enc_inputs)\n",
    "\n",
    "    # decoder padding mask - for the first sub layer\n",
    "    look_ahead_mask = create_look_ahead_mask(dec_inputs)\n",
    "\n",
    "    # decoder padding mask - for the second sub layer\n",
    "    dec_padding_mask = create_padding_mask(enc_inputs)\n",
    "\n",
    "    # encoder (type: keras model)\n",
    "    enc_outputs = encoder(inputs=[enc_inputs, enc_padding_mask])\n",
    "\n",
    "    # decoder (type: keras model)\n",
    "    dec_outputs = decoder(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측 출력층(단어 개수만큼 출력 존재)\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[enc_inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:49.497333Z",
     "start_time": "2022-11-17T08:18:49.482117Z"
    },
    "id": "YRY8cTiYMOSW"
   },
   "outputs": [],
   "source": [
    "# 손실 함수 (cross entropy)\n",
    "\n",
    "# 요약은 문장을 생성해내는 것이고, 이것은 단어 모음에 있는 단어 중\n",
    "# 현재 문장 뒤에 올 단어 하나를 선택하는 다중 클래스 분류 문제이다.\n",
    "# 따라서 cross entropy 함수를 손실함수로 사용한다.\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_OUTPUT_LENGTH -1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3O1CHNkMOSW"
   },
   "source": [
    "## 데이터 정보\n",
    "- size: 2176\n",
    "- sos: 8127\n",
    "- eos: 8128\n",
    "\n",
    "- BATCH_SIZE: 32\n",
    "- MAX_INPUT_LENGTH: 1000\n",
    "- MAX_OUTPUT_LENGTH: 600\n",
    "- VOCAB_SIZE: 8129\n",
    "\n",
    "## 하이퍼파라미터 (논문)\n",
    "- D_MODEL: 256 (512)\n",
    "- NUM_LAYERS: 3 (6)\n",
    "- NUM_HEADS: 8 (8)\n",
    "- DFF = 512 (1024)\n",
    "- DROPOUT: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:53.252883Z",
     "start_time": "2022-11-17T08:18:50.471636Z"
    },
    "id": "DYlyTA2SMOSW"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyper parameter (논문과 다름)\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 3\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# 인코더와 디코더 반환\n",
    "enc = encoder(BATCH_SIZE, VOCAB_SIZE, NUM_LAYERS, DFF, D_MODEL, NUM_HEADS, DROPOUT)\n",
    "dec = decoder(BATCH_SIZE, VOCAB_SIZE, NUM_LAYERS, DFF, D_MODEL, NUM_HEADS, DROPOUT)\n",
    "\n",
    "# 트랜스포머 모델 반환\n",
    "model = transformer(enc, dec, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:54.688686Z",
     "start_time": "2022-11-17T08:18:54.673854Z"
    },
    "id": "9cRyufStMOSW"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(step ** 0.5, step * (self.warmup_steps ** -1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:18:56.297480Z",
     "start_time": "2022-11-17T08:18:56.259694Z"
    },
    "id": "uLOWpXUAMOSW"
   },
   "outputs": [],
   "source": [
    "lr = CustomSchedule(d_model=D_MODEL, warmup_steps=4000) # 학습률\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(BATCH_SIZE, MAX_OUTPUT_LENGTH -1))\n",
    "\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T08:19:33.109965Z",
     "start_time": "2022-11-17T08:18:56.873927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/68 [..............................] - ETA: 26:51 - loss: 3.2045 - accuracy: 5.2170e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21056\\3076983285.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aicoding\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"training/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True, verbose=1)\n",
    "\n",
    "\n",
    "EPOCHS=50\n",
    "\n",
    "model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(user_input):\n",
    "    user_input = re.sub(r\"([?.!,])\", r\" \\1 \", user_input)\n",
    "    user_input = re.sub(\"[^ A-Za-z?.!,$%]+\", '', user_input)\n",
    "    user_input = user_input.strip()\n",
    "    \n",
    "    user_input = START_TOKEN + user_input + END_TOKEN\n",
    "    user_input = tf.keras.preprocessing.sequence.pad_sequences(user_input, maxlen=MAX_INPUT_LENGTH, padding='post')\n",
    "    \n",
    "    output = [START_TOKEN]\n",
    "    \n",
    "    for i in range(MAX_OUTPUT_LENGTH):\n",
    "        predictions = model(inputs=[user_input, output], training=False)\n",
    "        predictions = predictions[:, -1:, :]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "aicoding",
   "language": "python",
   "name": "aicoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8bf3ac2c94fcc354b18406fc8c4b51232d8b8a52e22d50326d4fda8485f476a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
