{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T17:46:19.968114Z",
     "start_time": "2022-11-19T17:46:14.632967Z"
    },
    "id": "DCoRPSSDMOSN"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "임포트\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T12:34:58.720145Z",
     "start_time": "2022-11-19T12:34:55.849596Z"
    },
    "id": "gov2I1jKMOSO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "데이터 파싱\n",
    "\n",
    "values = []\n",
    "sum_len = []\n",
    "def parse_file_content(root_path, is_summary, section, file_count):\n",
    "    folder_sort = [\"News Articles\", \"Summaries\"]\n",
    "\n",
    "    if is_summary:\n",
    "        index = 1\n",
    "    else:\n",
    "        index = 0\n",
    "   \n",
    "    # 파일 열기\n",
    "    file_name = ('%d' % file_count).zfill(3) + '.txt'\n",
    "    path = \"%s/%s/%s/%s\" % (root_path, folder_sort[index], section, file_name)\n",
    "    file = open(path, 'r')\n",
    "\n",
    "    # 파일 읽어서 content에 넣기\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    summary = lines[0]\n",
    "    sum_len.append(len(summary.split(' ')))\n",
    "    lines = lines[1:]\n",
    "    \n",
    "    content = ''\n",
    "    for line in lines:\n",
    "        content = content + ' ' + line.strip()\n",
    "        content = re.sub(r\"([?.!,])\", r\" \\1 \", content)\n",
    "        content = re.sub(\"[^ A-Za-z0-9?.!,$%]+\", '', content)\n",
    "        content = content.strip()\n",
    "\n",
    "    # 파일 닫기\n",
    "    file.close()\n",
    "\n",
    "    # 파일 내용 반환\n",
    "    return content, summary\n",
    "  \n",
    "def parse_folder(root_path, section):\n",
    "    folder_path = \"%s/Summaries/%s/\" % (root_path, section)\n",
    "    file_list = os.listdir(folder_path)\n",
    "    max_file_count = len(file_list)\n",
    "  \n",
    "    for i in range(1, max_file_count + 1):\n",
    "        # Text 데이터 가져오기\n",
    "        text, summary = parse_file_content(root_path=root_path, is_summary=False, section=section, file_count=i)\n",
    "    \n",
    "        # Summary 데이터 가져오기\n",
    "        #summary = parse_file_content(root_path=root_path, is_summary=True, section=section, file_count=i)\n",
    "\n",
    "        # values에 데이터 넣기\n",
    "        values.append([text, summary])\n",
    "\n",
    "# 모든 섹션들 데이터에 넣기\n",
    "root_path = \"./BBC News Summary\"\n",
    "parse_folder(root_path, \"business\")\n",
    "parse_folder(root_path, \"entertainment\")\n",
    "parse_folder(root_path, \"politics\")\n",
    "parse_folder(root_path, \"sport\")\n",
    "parse_folder(root_path, \"tech\")\n",
    "\n",
    "# 데이터프레임 만들어 csv 파일로 저장\n",
    "df = pd.DataFrame(values)\n",
    "df.columns = [\"Text\", \"Summary\"]\n",
    "df.to_csv(\"News_1.csv\", index=False)\n",
    "df.to_csv(\"News_1_text.txt\", sep=\" \", index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T17:46:23.600707Z",
     "start_time": "2022-11-19T17:46:23.520291Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DomdcrVhMOSP",
    "outputId": "e99191ce-04a1-4739-da31-b88d24a54dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 갯수 : 2225\n",
      "We need at least $20bn 10 . 6bn in investment and part of this has to come as foreign direct investment ,  said Mr Maran . Potential foreign investors will however need government approval before they increase their stake beyond 49% ,  Mr Maran said . Communications Minister Dayanidhi Maran said that there is a need to fund the fastgrowing mobile market . India has raised the limit for foreign direct investment in telecoms companies from 49% to 74% . Investment bank Morgan Stanley has forecast that Indias mobile market is likely to grow by about 40% a year until 2007 .\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "전처리\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"resources/News.csv\")\n",
    "\n",
    "# print(df)\n",
    "print(\"전체 데이터 갯수 :\", len(df))\n",
    "# print(df.isnull().sum())\n",
    "print(df[\"Summary\"][18]) # UTF-8 인코딩이 유로 표시를 '짙'으로 바꿈, 영어 빼고 제외시킬 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T17:46:27.902023Z",
     "start_time": "2022-11-19T17:46:26.515673Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjVw7TNeMOSQ",
    "outputId": "2499f0e3-7478-4d65-bd37-83f5fa5f685e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeWarner said fourth quarter sales rose 2% to $11 . 1bn from $10 . 9bn . For the fullyear ,  TimeWarner posted a profit of $3 . 36bn ,  up 27% from its 2003 performance ,  while revenues grew 6 . 4% to $42 . 09bn . Quarterly profits at US media giant TimeWarner jumped 76% to $1 . 13bn 600m for the three months to December ,  from $639m yearearlier . However ,  the company said AOLs underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues . Its profits were buoyed by oneoff gains which offset a profit dip at Warner Bros ,  and less users for AOL . For 2005 ,  TimeWarner is projecting operating earnings growth of around 5% ,  and also expects higher revenue and wider profit margins . It lost 464 , 000 subscribers in the fourth quarter profits were lower than in the preceding three quarters . Time Warners fourth quarter profits were slightly better than analysts expectations .\n",
      "[0, 26, 45, 658, 2005, 133, 1]\n",
      "hi my name is\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for content in df['Text']:\n",
    "    texts.append(content)\n",
    "\n",
    "summaries = []\n",
    "for content in df['Summary']:\n",
    "    summaries.append(content)\n",
    "\n",
    "print(summaries[0])\n",
    "# 단어 모음 생성\n",
    "tokenizer = BertWordPieceTokenizer(clean_text=True, lowercase=True)\n",
    "tokenizer.train(files=\"resources/News_text.txt\", vocab_size = 8000, special_tokens = [\n",
    "    \"[SOS]\", \"[EOS]\",\n",
    "])\n",
    "\n",
    "print(tokenizer.encode(\"[SOS] hi my name is [EOS]\").ids)\n",
    "print(tokenizer.decode(tokenizer.encode(\"[SOS] hi my name is [EOS]\").ids))\n",
    "\n",
    "START_TOKEN, END_TOKEN = [0], [1]  # <sos> 와 <eos>\n",
    "VOCAB_SIZE = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:53.395591Z",
     "start_time": "2022-11-19T15:45:48.791655Z"
    },
    "id": "t1HBzUgiMOSR"
   },
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 1000\n",
    "MAX_OUTPUT_LENGTH = 600\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    # 시작 토큰(sos)과 종료 토큰(eos) 포함\n",
    "    for (content1, content2) in zip(inputs, outputs):\n",
    "        content1 = START_TOKEN + tokenizer.encode(content1).ids + END_TOKEN\n",
    "        content2 = START_TOKEN + tokenizer.encode(content2).ids + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(content1)\n",
    "        tokenized_outputs.append(content2)\n",
    "    \n",
    "    # 길이를 1000, 600으로 맞춘다. 더 짧은 배열은 뒤에 0을 추가한다.\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=MAX_INPUT_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=MAX_OUTPUT_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "tok_texts, tok_summaries = tokenize_and_filter(texts, summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:53.411351Z",
     "start_time": "2022-11-19T15:45:53.397522Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlGEoN1cMOSR",
    "outputId": "aec62ad9-41fa-4e6d-9ee3-5cd18da70315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 데이터의 크기(shape) : (2225, 1000)\n",
      "요약 데이터의 크기(shape) : (2225, 600)\n"
     ]
    }
   ],
   "source": [
    "print(\"기사 데이터의 크기(shape) :\", tok_texts.shape)\n",
    "print(\"요약 데이터의 크기(shape) :\", tok_summaries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:53.456507Z",
     "start_time": "2022-11-19T15:45:53.415482Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTxfXCesMOSR",
    "outputId": "e8ea550f-08bf-46b3-9ff6-d23c2a38f59c"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'enc_inputs': tok_texts,\n",
    "        'dec_inputs': tok_summaries[:, :-1] # 마지막 패딩 0 제거\n",
    "    },\n",
    "    {\n",
    "        'outputs': tok_summaries[:, 1:] # 시작 토큰 제거\n",
    "    }\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "test_dataset = dataset.take(49)   # 앞에서 49개를 테스트 데이터로 뺌\n",
    "dataset = dataset.skip(49)   # 나머지 2176개가 학습 데이터가 됨\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # 메모리 사용을 위한 prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3K1gJeoMOSS"
   },
   "source": [
    "## transformer 아키텍처 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:55.187799Z",
     "start_time": "2022-11-19T15:45:55.158487Z"
    },
    "id": "YgbOK1gCMOSS"
   },
   "outputs": [],
   "source": [
    "# 인코더&디코더(포지셔널 인코딩)\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model, name=\"Positional_Encoding\"):\n",
    "        super(PositionalEncoding, self).__init__(name=name)\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        return position * (1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)))\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position = tf.range(position, dtype = tf.float32)[:, tf.newaxis],\n",
    "            i = tf.range(d_model, dtype = tf.float32)[tf.newaxis, :],\n",
    "            d_model = d_model\n",
    "        )\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines # even index -> sin\n",
    "        angle_rads[:, 1::2] = cosines # odd index  -> cos\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:55.531872Z",
     "start_time": "2022-11-19T15:45:55.524175Z"
    },
    "id": "naDI940YMOST"
   },
   "outputs": [],
   "source": [
    "# 패딩 마스크 생성\n",
    "def create_padding_mask(name):\n",
    "    inputs = tf.keras.Input(shape=(None,))\n",
    "    mask = tf.cast(tf.math.equal(inputs,0), tf.float32) # [[1,2,0,2,1]] => [[0.,0.,1.,0.,0.]]\n",
    "    return tf.keras.Model(inputs=inputs, outputs=mask[:,tf.newaxis, tf.newaxis, :], name=name) # 차원 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:55.892035Z",
     "start_time": "2022-11-19T15:45:55.884409Z"
    },
    "id": "lduANA-XMOSU"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask():\n",
    "    inputs = tf.keras.Input(shape=(None,))\n",
    "    seq_len = tf.shape(inputs)[1] # [[1,2,0]] => 3\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) # 모든 원소가 1인 하삼각행렬\n",
    "    padding_mask = create_padding_mask(name=\"look_ahead_padding\")(inputs=inputs) # x에서 0이었던 부분만 1로 바꿔진 행렬\n",
    "    return tf.keras.Model(inputs=inputs, outputs=tf.maximum(look_ahead_mask, padding_mask), name=\"look_ahead_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:56.268295Z",
     "start_time": "2022-11-19T15:45:56.246275Z"
    },
    "id": "0J4ViLosMOSU"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, d_model, num_heads, name=\"Multi_Head_Attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0 # d_model 사이즈의 행렬을 num_heads로 나눠야하기 때문\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # WQ, WK, WV 정의 : d_model 길이의 밀집층(가중치 행렬)\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model) # WQ (size: d_model * d_k)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model) # WK (size: d_model * d_k)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model) # WV (size: d_model * d_v)\n",
    "        \n",
    "        # WO\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model) # size: transpose hd_v * d_model\n",
    "    \n",
    "    def call(self, query, key, value, mask):\n",
    "        \n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 신경망 지나기\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 헤드 나누기\n",
    "        query = tf.reshape(query, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        key = tf.reshape(key, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        value = tf.reshape(value, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        \n",
    "        query = tf.transpose(query, perm=[0,2,1,3])\n",
    "        key = tf.transpose(key, perm=[0,2,1,3])\n",
    "        value = tf.transpose(value, perm=[0,2,1,3])\n",
    "\n",
    "        #스케일 닷 프로덕트 어텐션\n",
    "        multiple_QandK = tf.matmul(query, key, transpose_b=True) # 행렬 곱셈\n",
    "        d_k = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    \n",
    "        # 어텐션 에너지\n",
    "        energy = multiple_QandK / (d_k ** 0.5)\n",
    "        \n",
    "        # mask multihead attention 일 때\n",
    "        if mask is not None :\n",
    "            energy += (mask * -1e10)\n",
    "\n",
    "        # 어텐션 스코어\n",
    "        attention_weights = tf.nn.softmax(energy, axis = -1)\n",
    "\n",
    "        # scaled dot product attention\n",
    "        scaled_dot_attention = tf.transpose(tf.matmul(attention_weights, value), perm=[0,2,1,3]) # 행렬 곱셈\n",
    "\n",
    "        # concat \n",
    "        concat_attention = tf.reshape(scaled_dot_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # WO 밀집층 레이어 지나기\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:56.704329Z",
     "start_time": "2022-11-19T15:45:56.680108Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, dff, d_model, num_heads, dropout, name, epsilon=1e-6):\n",
    "        super(EncoderLayer, self).__init__(name=name)\n",
    "        self.batch_size = batch_size\n",
    "        self.dff = dff\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # layers\n",
    "        self.multi_head_attention = MultiHeadAttention(self.batch_size, self.d_model, self.num_heads)\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
    "        self.FFN1 = tf.keras.layers.Dense(units=self.dff, activation='relu')\n",
    "        self.FFN2 = tf.keras.layers.Dense(units=self.d_model)\n",
    "        \n",
    "    def call(self, inputs, padding_mask):\n",
    "        \n",
    "        # input size == output size\n",
    "        # dropout after each sublayer\n",
    "        \n",
    "        # first sub layer - Multi-head Attention\n",
    "        attention = self.multi_head_attention(query=inputs, key=inputs, value=inputs, mask=padding_mask)\n",
    "        attention = tf.keras.layers.Dropout(rate=self.dropout)(attention)\n",
    "        \n",
    "        # add, normalization\n",
    "        attention_norm = self.norm(inputs + attention)\n",
    "\n",
    "        # second sub layer - Feed Forward layer\n",
    "        outputs = self.FFN1(attention_norm)\n",
    "        outputs = self.FFN2(outputs)\n",
    "        outputs = tf.keras.layers.Dropout(rate=self.dropout)(outputs)\n",
    "\n",
    "        # add, normalization\n",
    "        outputs = self.norm(attention_norm + outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:57.202847Z",
     "start_time": "2022-11-19T15:45:57.178643Z"
    },
    "id": "xLctdIq6MOSU"
   },
   "outputs": [],
   "source": [
    "# real 인코더\n",
    "def encoder(batch_size, vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # input embedding, positional encoding\n",
    "    input_embedded = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
    "    input_embedded *= tf.cast(d_model, tf.float32) ** 0.5\n",
    "    input_positional_encoded = PositionalEncoding(position=vocab_size, d_model=d_model)(input_embedded)\n",
    "    enc_outputs = tf.keras.layers.Dropout(rate=dropout)(input_positional_encoded)\n",
    "    \n",
    "    # encoder layer * N\n",
    "    for i in range(num_layers):\n",
    "        enc_outputs = EncoderLayer(batch_size, dff, d_model, num_heads, dropout, \"encoder_layer_\"+str(i))(enc_outputs, padding_mask)\n",
    "            \n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=enc_outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaP9rLUKMOSV"
   },
   "source": [
    "## 디코더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:58.154473Z",
     "start_time": "2022-11-19T15:45:58.143327Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, dff, d_model, num_heads, dropout,  name, epsilon=1e-6):\n",
    "        super(DecoderLayer, self).__init__(name=name)\n",
    "        self.batch_size = batch_size\n",
    "        self.dff = dff\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # layers\n",
    "        self.masked_attention = MultiHeadAttention(self.batch_size, self.d_model, self.num_heads, name=\"Multi_Head_Attention_1\")\n",
    "        self.encoder_decoder_attention = MultiHeadAttention(self.batch_size, self.d_model, self.num_heads, name=\"Multi_Head_Attention_2\")\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
    "        self.FFN1 = tf.keras.layers.Dense(units=self.dff, activation=\"relu\")\n",
    "        self.FFN2 = tf.keras.layers.Dense(units=self.d_model)\n",
    "    \n",
    "    def call(self, inputs, enc_outputs, look_ahead_mask, padding_mask):\n",
    "        \n",
    "        # input size == output size\n",
    "        # dropout after each sublayer\n",
    "        \n",
    "        # first sub layer - masked multi-head attention\n",
    "        attention1 = self.masked_attention(query=inputs, key=inputs, value=inputs, mask=look_ahead_mask)\n",
    "\n",
    "        # add, normorlization\n",
    "        attention1 = self.norm(attention1 + inputs)\n",
    "\n",
    "        # second sub layer - encoder-decoder attention\n",
    "        attention2 = self.encoder_decoder_attention(query=attention1, key=enc_outputs, value=enc_outputs, mask=padding_mask)\n",
    "        attention2 = tf.keras.layers.Dropout(rate=self.dropout)(attention2)\n",
    "\n",
    "        # add, normorlization\n",
    "        attention2 = self.norm(attention2 + attention1)\n",
    "\n",
    "        # third sub layer - Feed Forward layer (dense layer)\n",
    "        feed_forward_output = self.FFN1(attention2)\n",
    "        feed_forward_output = self.FFN2(feed_forward_output)\n",
    "        feed_forward_output = tf.keras.layers.Dropout(rate=self.dropout)(feed_forward_output)\n",
    "\n",
    "        # add, normorlization\n",
    "        outputs = self.norm(attention2 + feed_forward_output)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:58.589905Z",
     "start_time": "2022-11-19T15:45:58.571744Z"
    },
    "id": "jgqFA45fMOSV"
   },
   "outputs": [],
   "source": [
    "def decoder(batch_size, vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    # output embedding\n",
    "    output_embedded = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
    "    output_embedded *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    output_embedded = PositionalEncoding(position=vocab_size, d_model=d_model)(output_embedded)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(output_embedded)\n",
    "    \n",
    "    # decoder layer * N\n",
    "    for i in range(num_layers):\n",
    "        dec_outputs = DecoderLayer(batch_size, dff, d_model, num_heads, dropout, \"decoder_layer_\"+str(i))(dec_outputs, enc_outputs, look_ahead_mask, padding_mask)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask], outputs=dec_outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sTDhtTNMOSV"
   },
   "source": [
    "## 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:59.308332Z",
     "start_time": "2022-11-19T15:45:59.298756Z"
    },
    "id": "OCUDKICKMOSV"
   },
   "outputs": [],
   "source": [
    "def transformer(encoder, decoder, vocab_size, name=\"transformer\"):\n",
    "    \n",
    "    # encoder input (type: keras tensor)\n",
    "    enc_inputs = tf.keras.Input(shape=(None,), name=\"enc_inputs\")\n",
    "\n",
    "    # decoder input (type: keras tensor)\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(name=\"enc_padding_mask\")(enc_inputs)\n",
    "\n",
    "    # decoder padding mask - for the first sub layer\n",
    "    look_ahead_mask = create_look_ahead_mask()(dec_inputs)\n",
    "\n",
    "    # decoder padding mask - for the second sub layer\n",
    "    dec_padding_mask = create_padding_mask(name=\"dec_padding_mask\")(enc_inputs)\n",
    "\n",
    "    # encoder (type: keras model)\n",
    "    enc_outputs = encoder(inputs=[enc_inputs, enc_padding_mask])\n",
    "\n",
    "    # decoder (type: keras model)\n",
    "    dec_outputs = decoder(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측 출력층(단어 개수만큼 출력 존재)\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[enc_inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:45:59.667803Z",
     "start_time": "2022-11-19T15:45:59.648785Z"
    },
    "id": "YRY8cTiYMOSW"
   },
   "outputs": [],
   "source": [
    "# 손실 함수 (cross entropy)\n",
    "\n",
    "# 요약은 문장을 생성해내는 것이고, 이것은 단어 모음에 있는 단어 중\n",
    "# 현재 문장 뒤에 올 단어 하나를 선택하는 다중 클래스 분류 문제이다.\n",
    "# 따라서 cross entropy 함수를 손실함수로 사용한다.\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_OUTPUT_LENGTH -1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3O1CHNkMOSW"
   },
   "source": [
    "## 데이터 정보\n",
    "- size: 2176\n",
    "- sos: 8127\n",
    "- eos: 8128\n",
    "\n",
    "- BATCH_SIZE: 32\n",
    "- MAX_INPUT_LENGTH: 1000\n",
    "- MAX_OUTPUT_LENGTH: 600\n",
    "- VOCAB_SIZE: 8129\n",
    "\n",
    "## 하이퍼파라미터 (논문)\n",
    "- D_MODEL: 256 (512)\n",
    "- NUM_LAYERS: 3 (6)\n",
    "- NUM_HEADS: 8 (8)\n",
    "- DFF = 512 (1024)\n",
    "- DROPOUT: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:03.493988Z",
     "start_time": "2022-11-19T15:46:00.446651Z"
    },
    "id": "DYlyTA2SMOSW"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# hyper parameter (논문과 다름)\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 3\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# 인코더와 디코더 반환\n",
    "enc = encoder(BATCH_SIZE, VOCAB_SIZE, NUM_LAYERS, DFF, D_MODEL, NUM_HEADS, DROPOUT)\n",
    "dec = decoder(BATCH_SIZE, VOCAB_SIZE, NUM_LAYERS, DFF, D_MODEL, NUM_HEADS, DROPOUT)\n",
    "\n",
    "# 트랜스포머 모델 반환\n",
    "model = transformer(enc, dec, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:03.541281Z",
     "start_time": "2022-11-19T15:46:03.496834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " enc_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Functional)  (None, 1, 1, None)   0           ['enc_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    3627776     ['enc_inputs[0][0]',             \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Functional)   (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Functional)  (None, 1, 1, None)   0           ['enc_inputs[0][0]']             \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    4417280     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8000)   2056000     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,101,056\n",
      "Trainable params: 10,101,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:03.556872Z",
     "start_time": "2022-11-19T15:46:03.543410Z"
    },
    "id": "9cRyufStMOSW"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(step ** 0.5, step * (self.warmup_steps ** -1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:03.587119Z",
     "start_time": "2022-11-19T15:46:03.560061Z"
    },
    "id": "uLOWpXUAMOSW"
   },
   "outputs": [],
   "source": [
    "lr = CustomSchedule(d_model=D_MODEL, warmup_steps=4000) # 학습률\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(BATCH_SIZE, MAX_OUTPUT_LENGTH -1))\n",
    "\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:10.241879Z",
     "start_time": "2022-11-19T15:46:10.241879Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_final/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True, verbose=1)\n",
    "\n",
    "EPOCHS=50\n",
    "model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:15.177524Z",
     "start_time": "2022-11-19T15:46:15.168447Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(user_input):\n",
    "    user_input = re.sub(r\"([?.!,])\", r\" \\1 \", user_input)\n",
    "    user_input = re.sub(\"[^ A-Za-z?.!,$%]+\", '', user_input)\n",
    "    user_input = user_input.strip()\n",
    "\n",
    "    user_input = tf.expand_dims(START_TOKEN + tokenizer.encode(user_input).ids + END_TOKEN, 0)\n",
    "    print(len(user_input[0]))\n",
    "    \n",
    "    return user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:47:36.641648Z",
     "start_time": "2022-11-19T15:47:36.622199Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction(user_input):\n",
    "    \n",
    "    enc = encoder(BATCH_SIZE, VOCAB_SIZE, NUM_LAYERS, DFF, D_MODEL, NUM_HEADS, DROPOUT)\n",
    "    dec = decoder(BATCH_SIZE, VOCAB_SIZE, NUM_LAYERS, DFF, D_MODEL, NUM_HEADS, DROPOUT)\n",
    "    \n",
    "    trained_model = transformer(enc, dec, VOCAB_SIZE)\n",
    "    trained_model.load_weights(\"training_final/cp.ckpt\").expect_partial()\n",
    "    \n",
    "    output = tf.expand_dims(END_TOKEN, 0)\n",
    "    print(user_input.shape)\n",
    "    \n",
    "    for i in range(MAX_OUTPUT_LENGTH):\n",
    "        predictions = trained_model(inputs=[user_input, output], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        #print(predicted_id)\n",
    "\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "        \n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:23.693379Z",
     "start_time": "2022-11-19T15:46:23.675839Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(user_input):\n",
    "    preprocessed_input = preprocessing(user_input)\n",
    "    predicted_output = get_prediction(preprocessed_input)\n",
    "\n",
    "    predicted_output = tokenizer.decode(predicted_output)\n",
    "  \n",
    "    print('Input:', user_input)\n",
    "    print('Output:', predicted_output)\n",
    "\n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:46:24.083655Z",
     "start_time": "2022-11-19T15:46:24.064375Z"
    }
   },
   "outputs": [],
   "source": [
    "article = \"\"\"Ad sales boost Time Warner profit\n",
    "\n",
    "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
    "\n",
    "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
    "\n",
    "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
    "\n",
    "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
    "\n",
    "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T15:48:06.950298Z",
     "start_time": "2022-11-19T15:47:39.711324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n",
      "(1, 542)\n",
      "Input: Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n",
      "Output: profit for the us sales for all contributing company to profit thanks to its profits by all time for the three years, while the company has increased by the company has increased by the $ 40. earlier this year in the us growth remains at $ 17. 36bn, less than $ 16. 36bn, while the $ 16bn 48x.fastner has reported a profit in the us sales of $ 1. 2m to $ 10. 0. 7 %.fastner has been wippy, the company, while its just $ 1. 7bn rupees $ 1. 0. 0. 50bn, while sales rose 23bn, after throughout 2004 was now has less than in the us alone. for the company also said aols for the us dollar has increased pressure from the us.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'profit for the us sales for all contributing company to profit thanks to its profits by all time for the three years, while the company has increased by the company has increased by the $ 40. earlier this year in the us growth remains at $ 17. 36bn, less than $ 16. 36bn, while the $ 16bn 48x.fastner has reported a profit in the us sales of $ 1. 2m to $ 10. 0. 7 %.fastner has been wippy, the company, while its just $ 1. 7bn rupees $ 1. 0. 0. 50bn, while sales rose 23bn, after throughout 2004 was now has less than in the us alone. for the company also said aols for the us dollar has increased pressure from the us.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "aicoding",
   "language": "python",
   "name": "aicoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8bf3ac2c94fcc354b18406fc8c4b51232d8b8a52e22d50326d4fda8485f476a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
